{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opioid Addiction Project\n",
    "## Notebook 06: Full Pipeline\n",
    "\n",
    "This notebook is intended to simulate the full pipeline using .py modules, starting with submitting a user's input, preprocessing that input, then running it through prediction tasks, resulting in the final output of the user's prediction scores.\n",
    "\n",
    "### W210, Capstone\n",
    "Summer 2019\n",
    "\n",
    "Team:  Cameron Kennedy, Aditi Khullar, Rachel Kramer, Sharad Varadarajan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load Libraries and Set Global Variables\n",
    "This analysis is performed in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas Version 0.24.2\n"
     ]
    }
   ],
   "source": [
    "#Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib  #Used to save/load (pickle) models\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "from scipy import stats\n",
    "\n",
    "#Custom data prep function used in both training and prediction \n",
    "import OpioidDataPrep as odp\n",
    "import OpioidExecution as oe\n",
    "\n",
    "#Set initial parameter(s)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.max_columns = 150\n",
    "dataDir = './data/'\n",
    "\n",
    "print('Pandas Version', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simulate User Data\n",
    "\n",
    "This section simulates the user entering various responses to questions. In the actual web tool, this input will come in the form of a dictionary, therefore this data should mimic that format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NAME': 'Joe Capstone', 'IRSEX': 1, 'IREDUHIGHST2': 11, 'AGE2': 27, 'IRALCRC': 1, 'IRALCFY': 300, 'BNGDRKMON': 1, 'HVYDRKMON': 1, 'IRALCAGE': 13, 'TXYRRECVD2': 1, 'TXEVRRCVD2': 1, 'IRCIGRC': 1, 'CIGDLYMO': 1, 'CIGAGE': 13, 'PIPEVER': 1, 'IRCGRRC': 1, 'IRSMKLSSREC': 1, 'IRMJRC': 1, 'MJYRTOT': 300, 'FUMJ18': 1, 'FUMJ21': 1, 'ADDPREV': 1, 'ADDSCEV': 1, 'BOOKED': 1}\n"
     ]
    }
   ],
   "source": [
    "#Simulate User Input\n",
    "\n",
    "inputDict = dict()\n",
    "\n",
    "'''\n",
    "[{'NAME': 'sharad', 'AGE2': 27, 'IRSEX': 1, 'IREDUHIGHST2': 11}, {'IRALCAGE': 13, 'IRALCRC': 1, 'IRALCFY': 300, \n",
    "'BNGDRKMON': 1, 'HVYDRKMON': 1}, {'TXYRRECVD2': 1, 'TXEVRRCVD2': 1}, {'IRCIGRC': 1, 'CIGDLYMO': 1, 'CIGAGE': 13, \n",
    "'PIPEVER': 1, 'IRCGRRC': 1, 'IRSMKLSSREC': 1}, {'IRMJRC': 1, 'MJYRTOT': 300, 'FUMJ18': 1, 'FUMJ21': 1}, \n",
    "{'ADDPREV': 1, 'ADDSCEV': 1}, {'BOOKED': 1}]\n",
    "'''\n",
    "\n",
    "#DEMOGRAPHICS\n",
    "inputDict['NAME'] = 'Joe Capstone' #We will delete this column\n",
    "inputDict['IRSEX'] = 1 #Gender: 'Male' or 'Female'\n",
    "inputDict['IREDUHIGHST2'] = 11 #Education:\n",
    "inputDict['AGE2'] = 27 #Age\n",
    "    \n",
    "#ALCOHOL\n",
    "inputDict['IRALCRC'] = 1 #(Alcohol Recency)\n",
    "inputDict['IRALCFY'] = 300 #(Alcohol Frequency Past Year)\n",
    "inputDict['BNGDRKMON'] = 1 #(Binge drinking, past 30 days)\n",
    "inputDict['HVYDRKMON'] = 1 #(Heavy drinking, past 30 days)\n",
    "inputDict['IRALCAGE'] = 13 #(First time used alcohol)\n",
    "\n",
    "#DRUGS + ALCOHOL\n",
    "inputDict['TXYRRECVD2'] = 1 #(Ever alcohol/drug treatment, past yr)\n",
    "inputDict['TXEVRRCVD2'] = 1 #(Ever alcohol/drug treatment, lifetime)\n",
    "\n",
    "\n",
    "#TOBACCO\n",
    "inputDict['IRCIGRC'] = 1 #(Tobacco Recency, incl. Never)\n",
    "inputDict['CIGDLYMO'] = 1 #(Tobacco 30+ consecutive days)\n",
    "inputDict['CIGAGE'] = 13 #(Tobacco Use Daily)\n",
    "inputDict['PIPEVER'] = 1 #(Ever smoked a pipe)\n",
    "inputDict['IRCGRRC'] = 1 #(Cigar recency)\n",
    "inputDict['IRSMKLSSREC'] = 1 #(Smokeless tobacco recency)\n",
    "    \n",
    "#WEED\n",
    "inputDict['IRMJRC'] = 1 #(Weed recency)\n",
    "inputDict['MJYRTOT'] = 300 #(Weed days in past year)\n",
    "inputDict['FUMJ18'] = 1 #(First used weed prior to age 18)\n",
    "inputDict['FUMJ21'] = 1 #(First used weed prior to age 21)\n",
    "    \n",
    "#DEPRESSION\n",
    "inputDict['ADDPREV'] = 1 #(Several days of depression)\n",
    "inputDict['ADDSCEV'] = 1 #(Several days of discouraged about life)\n",
    "    \n",
    "##OTHER\n",
    "inputDict['BOOKED'] = 1 #(Ever arrested & booked)\n",
    "\n",
    "print(inputDict)\n",
    "\n",
    "#Convert to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.b Web App Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camke\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Probability: 88%\n",
      "Percentile of Predicted Probability: 100%\n",
      "Feature Importance (sorted low to high):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'IREDUHIGHST2': -0.022064632534958745,\n",
       " 'IRSEX': -0.0035416959439998324,\n",
       " 'FUMJ21': -0.0017268124960524575,\n",
       " 'CIGDLYMO': -0.0015330947424896622,\n",
       " 'IRALCRC': -0.0014857265828542381,\n",
       " 'BOOKED': 0.005262318335352478,\n",
       " 'ADDSCEV': 0.008098832332624248,\n",
       " 'ADDPREV': 0.01198750346410723,\n",
       " 'CIGAGE': 0.016979258555984502,\n",
       " 'IRCIGRC': 0.020177570991787196,\n",
       " 'IRCGRRC': 0.022628753172388667,\n",
       " 'HVYDRKMON': 0.025032005624697675,\n",
       " 'IRALCFY': 0.02573143315830575,\n",
       " 'PIPEVER': 0.025979095721158616,\n",
       " 'IRSMKLSSREC': 0.02721074709055188,\n",
       " 'BNGDRKMON': 0.031940937251929424,\n",
       " 'IRMJRC': 0.03873099257158695,\n",
       " 'TXEVRRCVD2': 0.03877888524096162,\n",
       " 'IRALCAGE': 0.047310605419703784,\n",
       " 'TXYRRECVD2': 0.05790152850841173,\n",
       " 'MJYRTOT': 0.0968940547288994,\n",
       " 'AGE2': 0.10206200675977697,\n",
       " 'FUMJ18': 0.11324376454000534}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Web App Test\n",
    "runWebAppTest = True\n",
    "predFI = None\n",
    "if runWebAppTest:\n",
    "    predProb, predPercentile, predFI = oe.generateReport(inputDict)\n",
    "    print('Predicted Probability: {:.0%}'.format(predProb))\n",
    "    print('Percentile of Predicted Probability: {:.0%}'.format(predPercentile))\n",
    "    print('Feature Importance (sorted low to high):')\n",
    "predFI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert inputs to list (pandas conversion to dataframe requires dict values to be lists)\n",
    "if not runWebAppTest: \n",
    "    '''If we run our web app test, these next two lines already run in that and thus\n",
    "    can't be run here (they'll double-list the dictionary)\n",
    "    '''\n",
    "    for k in inputDict:\n",
    "        inputDict[k] = [inputDict[k]]\n",
    "print(inputDict)\n",
    "\n",
    "#Convert dict to dataframe\n",
    "df = pd.DataFrame.from_dict(inputDict)\n",
    "\n",
    "#Run preprocessing on dataframe\n",
    "df = odp.preprocess(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resort by column name (necessary to feed the model)\n",
    "c = list(df.columns)\n",
    "c.sort()\n",
    "df = df[c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate Predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load Models\n",
    "model = joblib.load(dataDir+'modelXGB.model')\n",
    "explainer = joblib.load(dataDir+'calibXGB.explainer') ###NEED TO FIX THIS NAME\n",
    "probs = np.load(dataDir+'modelXGBPredProbs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Prediciton\n",
    "predM = model.predict_proba(df)[0][1]\n",
    "print('Predicted Probability: {:.0%}'.format(predM))\n",
    "\n",
    "#Calculate Percentile\n",
    "pct = stats.percentileofscore(probs, predM)/100\n",
    "print('Percentile of Predicted Probability: {:.0%}'.format(pct))\n",
    "\n",
    "#Generate shapley values from this row\n",
    "shapVal = explainer.shap_values(df)\n",
    "\n",
    "#Aggregate shapley values for one-hot vectors\n",
    "shapDict = defaultdict(list) #Handy: creates blank list if key doesn't exist, or appends to it if it does.\n",
    "\n",
    "#Get everything before the '_' character of each column name\n",
    "#Then create the column index numbers for those keys \n",
    "#These numbers correspond to the locations in the shapley output array\n",
    "for i, colName in enumerate(df.columns):\n",
    "    shapDict[colName.split('_')[0]].append(i)\n",
    "    \n",
    "#Make a list of aggregated values shapley\n",
    "for k in shapDict: #Loop through every key in the dict\n",
    "    shapSum = 0.0 #Reset to 0\n",
    "    for index in shapDict[k]: #Loop through every item in the key's value (a list of column indexes)\n",
    "        shapSum += shapVal[0][index] #Add the value for each item\n",
    "    shapDict[k] = shapSum #Replace the list with the aggregated shapley value (the sum of each individual value)\n",
    "\n",
    "sortedShapDict = dict(sorted(shapDict.items(), key=operator.itemgetter(1)))\n",
    "print('Feature Importance (sorted low to high):')\n",
    "sortedShapDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
